{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "onecode_predict_kospi.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZBhatHgmZEWN6GbMf0BfPV5THxKAF7Ez",
      "authorship_tag": "ABX9TyM9AmKt3zj09SXqcNNqlisC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhw0772/deepstock/blob/master/onecode_predict_kospi_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl3_DUgr1mjM",
        "colab_type": "text"
      },
      "source": [
        "1. 유틸 로드\n",
        "\n",
        "ctrl +F5 : 구글드라이브 마운트\n",
        "ctrl +F9 : 모든 코드 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vuSi9oR54Kb",
        "colab_type": "text"
      },
      "source": [
        "2. 데이터 저장 / 읽기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsgPuiIw011f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing \n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import datetime\n",
        "import pandas_datareader as pdr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "DEBUG = 1\n",
        "\n",
        "KOSPI_LIST_FILE= 'drive/My Drive/kospi/data/kospi_list.csv'\n",
        "KOSPI_DATA_ROOT= 'drive/My Drive/kospi/data/'\n",
        "\n",
        "TRAIN_START=datetime.datetime(2015, 1, 1)\n",
        "TRAIN_END=datetime.datetime(2018, 12, 31)\n",
        "\n",
        "TEST_START=datetime.datetime(2019, 1, 1)\n",
        "TEST_END=datetime.datetime(2020, 1, 1)\n",
        "\n",
        "def get_stock_hist(code,start,end):\n",
        "\n",
        "  if(DEBUG):\n",
        "    print (code)\n",
        "  try :\n",
        "    info = pdr.get_data_yahoo(code, \n",
        "                          start=start, \n",
        "                          end=end)\n",
        "  except:\n",
        "    if(DEBUG):\n",
        "      print('no data, skip')\n",
        "    df_empty = pd.DataFrame({'A' : []})\n",
        "    return df_empty\n",
        "\n",
        "  return info\n",
        "\n",
        "def save_preproc_kospi(kospi_list,_start,_end,_period,_filename):\n",
        "  start = _start\n",
        "  end = _end\n",
        "  period = _period\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "  train_x =[]\n",
        "  train_y =[]\n",
        "\n",
        "  valid_x =[]\n",
        "  valid_y =[]\n",
        "\n",
        "  test_x =[]\n",
        "  test_y =[]\n",
        "\n",
        "  code_cnt = 0\n",
        "  total_code_num = len(kospi_list)\n",
        "\n",
        "  for code in kospi_list:\n",
        "\n",
        "    print (str(code_cnt)+\"/\"+str(total_code_num))\n",
        "  \n",
        "    if(code.isdigit() == True):\n",
        "\n",
        "      hist=get_stock_hist(code+'.KS',start,end)\n",
        "\n",
        "      if(hist.empty):\n",
        "        continue\n",
        "\n",
        "      total_len=len(hist)\n",
        "      start_idx =0\n",
        "      end_idx =start_idx+period+1\n",
        "\n",
        "      code_cnt +=1 \n",
        "\n",
        "      while end_idx < total_len:\n",
        "        split_data=hist[start_idx:end_idx] ## start_idx ~ end_idx  # 0~30 \n",
        "        feature = split_data.iloc[:,4:6] ## adj_close, volume\n",
        "        scaled_feature = min_max_scaler.fit_transform(feature)\n",
        "        label = scaled_feature[30][1] - scaled_feature[29][1]\n",
        "\n",
        "        if(DEBUG>1 and end_idx ==31):\n",
        "          plt.plot(scaled_feature)\n",
        "          plt.show()\n",
        "\n",
        "        if(label >0):\n",
        "          label = 1\n",
        "        else:\n",
        "          label = 0\n",
        "\n",
        "        start_idx +=1\n",
        "        end_idx +=1\n",
        "\n",
        "        train_x.append(scaled_feature[:-1])\n",
        "        train_y.append(label)\n",
        "\n",
        "  train_x = np.array(train_x)\n",
        "  train_y = np.array(train_y)\n",
        "\n",
        "  print (train_x.shape)\n",
        "  print (train_y.shape)\n",
        "\n",
        "  np.save(_filename+\"_x\",train_x)\n",
        "  np.save(_filename+\"_y\",train_y)\n",
        "\n",
        "def make_data(period,d_name):\n",
        "\n",
        "  kospi_list = pd.read_csv(KOSPI_LIST_FILE,error_bad_lines=False)['종목코드']\n",
        "  print ('training data making')\n",
        "  period = period\n",
        "\n",
        "  folder_path = os.path.join(KOSPI_DATA_ROOT,d_name)\n",
        "\n",
        "  if(os.path.exists(folder_path)==False):\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "  save_preproc_kospi(kospi_list,TRAIN_START,TRAIN_END,period,os.path.join(folder_path,'train'))\n",
        "\n",
        "  print ('testing data making')\n",
        "  period = period\n",
        "  save_preproc_kospi(kospi_list,TEST_START,TEST_END,period,os.path.join(folder_path,'test'))\n",
        "\n",
        "\n",
        "def load_data(d_name):\n",
        "\n",
        "  folder_path = os.path.join(KOSPI_DATA_ROOT,d_name)\n",
        "\n",
        "  kospi_train_x = np.load(os.path.join(folder_path,'train_x.npy'))\n",
        "  kospi_train_y = np.load(os.path.join(folder_path,'train_y.npy'))\n",
        "\n",
        "  kospi_test_x = np.load(os.path.join(folder_path,'test_x.npy'))\n",
        "  kospi_test_y = np.load(os.path.join(folder_path,'test_y.npy'))\n",
        "\n",
        "  kospi_train_y=to_categorical(kospi_train_y)\n",
        "  kospi_test_y=to_categorical(kospi_test_y)\n",
        "\n",
        "\n",
        "  return [kospi_train_x,kospi_train_y,kospi_test_x,kospi_test_y]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STiIn7dJ-DWz",
        "colab_type": "text"
      },
      "source": [
        "3. 모델 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-54Sbfg-Gph",
        "colab_type": "code",
        "outputId": "6d744dbc-5e31-4f46-9391-5cfd8634f5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.models import model_from_json\n",
        "\n",
        "KOSPI_MODEL_ROOT= 'drive/My Drive/kospi/model'\n",
        "\n",
        "def save_model_arch(model,model_name):\n",
        "  model_json = model.to_json()\n",
        "  with open(model_name, \"w\") as json_file : \n",
        "    json_file.write(model_json)\n",
        "\n",
        "def create_lstm_v1():\n",
        "  inputs = Input(shape=(30,2))\n",
        "  lstm1 = LSTM(units=50, return_sequences=True)(inputs)\n",
        "  dropout1 = Dropout(0.2)(lstm1)\n",
        "  lstm2 = LSTM(units=50, return_sequences=True)(dropout1)\n",
        "  dropout2 = Dropout(0.2)(lstm2)\n",
        "  lstm3 = LSTM(units=50)(dropout2)\n",
        "  dropout3 = Dropout(0.2)(lstm3)\n",
        "  softmax = Dense(units=2,activation='softmax')(dropout3)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "  metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def make_model(model_name):\n",
        "    if model_name == 'm1':\n",
        "      model=create_lstm_v1()\n",
        "      folder_path= os.path.join(KOSPI_MODEL_ROOT,model_name)\n",
        "\n",
        "      if(os.path.exists(folder_path)==False):\n",
        "        os.mkdir(folder_path)\n",
        "      save_model_arch(model,os.path.join(folder_path,model_name+\".json\"))\n",
        "\n",
        "def load_model_arch(model_name):\n",
        "  real_path=os.path.join(KOSPI_MODEL_ROOT,model_name,model_name+\".json\")\n",
        "  json_file = open(real_path)\n",
        "  loaded_model_json=json_file.read()\n",
        "  json_file.close()\n",
        "  loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "  loaded_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "  metrics=['accuracy'])\n",
        "  return loaded_model\n",
        "\n",
        "def load_model_ckpt (nodel_arch,model_name,_epoch):\n",
        "  ckpt = os.path.join(KOSPI_MODEL_ROOT,model_name,'model-{epoch:04d}.h5')\n",
        "  nodel_arch.load_weights(ckpt.format(epoch=_epoch),by_name=True)\n",
        "  return nodel_arch\n",
        "\n",
        "\n",
        "#make_model('m1')\n",
        "#model = load_model_arch('m1')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUiiQ_vMM4Rr",
        "colab_type": "text"
      },
      "source": [
        "4. 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fWnYyZKM3rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "KOSPI_MODEL_ROOT= 'drive/My Drive/kospi/model'\n",
        "\n",
        "\n",
        "def train_model(ckpt_model_name,model,data,epoch,batch_size,initial_epoch):\n",
        "  \n",
        "  ckpt_path = os.path.join(KOSPI_MODEL_ROOT,ckpt_model_name,'model-{epoch:04d}.h5')\n",
        "\n",
        "  cp_callback = ModelCheckpoint(\n",
        "    ckpt_path, verbose=1, save_weights_only=True,\n",
        "    period=1)\n",
        "\n",
        "  hist = model.fit(data[0],data[1],batch_size=batch_size,\n",
        "                   validation_split=0.3, \n",
        "                   epochs=epoch,\n",
        "                   initial_epoch=initial_epoch,\n",
        "                   callbacks = [cp_callback],validation_freq=1)\n",
        "  \n",
        "  return hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBp039m3QAZL",
        "colab_type": "text"
      },
      "source": [
        "5.분석\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjoJnmIBQDHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def disp_hist(hist):\n",
        "  fig, loss_ax = plt.subplots()\n",
        "  acc_ax = loss_ax.twinx()\n",
        "\n",
        "  loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "  loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "  loss_ax.set_xlabel('epoch')\n",
        "  loss_ax.set_ylabel('loss')\n",
        "  loss_ax.legend(loc='upper left')\n",
        "\n",
        "  acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "  acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "  acc_ax.set_ylabel('accuracy')\n",
        "  acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "KOSPI_MODEL_ROOT= 'drive/My Drive/kospi/model'\n",
        "\n",
        "def draw_pr_curve(model_name,test_x,test_y,_epoch,th):\n",
        "\n",
        "    test_x=test_x[:,:,:]\n",
        "    test_y=test_y[:]\n",
        "\n",
        "    model=load_model_arch(model_name)\n",
        "    model=load_model_ckpt(model,model_name,_epoch)\n",
        "\n",
        "    predict = model.predict(test_x,batch_size=10240)\n",
        "    y_scores=predict[:,1]\n",
        "    y_true=test_y[:,1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "    plt.plot(recall, precision, label='Precision-Recall curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "\n",
        "    idx= np.where(recall<th)[0][0]\n",
        "\n",
        "    print('precision')\n",
        "    print (precision[idx])\n",
        "    print ('recall')\n",
        "    print (recall[idx])\n",
        "    print ('threhold')\n",
        "    print (thresholds[idx])\n",
        "\n",
        "    return precision[idx],recall[idx],thresholds[idx],y_true,y_scores\n",
        "\n",
        "def pick_best_model(model_name,test_x,test_y,max_epoch):\n",
        "\n",
        "  acc_list=[]\n",
        "  loss_list=[]\n",
        "  epoch_list=[]\n",
        "\n",
        "  model=load_model_arch(model_name)\n",
        "\n",
        "  for epoch in range(1,max_epoch):\n",
        "    model=load_model_ckpt(model,model_name,epoch)\n",
        "    loss,acc=model.evaluate(test_x,test_y,batch_size=10240)\n",
        "    acc_list.append(acc)\n",
        "    loss_list.append(loss)\n",
        "    epoch_list.append(epoch)\n",
        "  \n",
        "  plt.plot(epoch_list,acc_list,color='green')\n",
        "  plt.plot(epoch_list,loss_list,color='red')\n",
        "  plt.show()\n",
        "\n",
        "  best_idx = np.array(acc_list).argmax()\n",
        "\n",
        "  return (np.array(acc_list).argmax()+1,acc_list[best_idx],loss_list[best_idx])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2eqrHz0Yo6Y",
        "colab_type": "text"
      },
      "source": [
        "6. 백테스팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrXOlYxAYuuC",
        "colab_type": "code",
        "outputId": "ef17bb50-bdc9-446d-be4e-0ab4e5ede929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "MAX_EPOCH = 79\n",
        "DATA_NAME = 'd1'\n",
        "MODEL_NAME = 'm1'\n",
        "MIN_RECALL = 0.1\n",
        "\n",
        "data=load_data(DATA_NAME)\n",
        "# epoch,acc,val=pick_best_model(MODEL_NAME,data[2],data[3],MAX_EPOCH)\n",
        "# print (epoch,acc,val)\n",
        "\n",
        "epoch=45\n",
        "print (epoch)\n",
        "precision,recall,threshold,y_true,y_scores=draw_pr_curve(MODEL_NAME,data[2],data[3],epoch,MIN_RECALL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU5f338fc3G7tBCMiSABGRRZYI\nUVBEUURAUeuKS1ttXapW1F+tSp9qRauPP63aarFV60JrreJSfQBxKcpeEYKEfQt7AAUCsiSEkOT7\n/DEDhCWTIclkkvB5XRcXc5Y58+W+hnxy7vuc+5i7IyIiUpqYaBcgIiLVm4JCRERCUlCIiEhICgoR\nEQlJQSEiIiHFRbuAY5WUlOTt2rWLdhkiIjXKnDlztrp7s/K8t8YFRbt27cjIyIh2GSIiNYqZrS3v\ne9X1JCIiISkoREQkJAWFiIiEpKAQEZGQFBQiIhKSgkJEREKKWFCY2RtmttnMFpay3czsRTPLMrP5\nZtYzUrWIiEj5RfI+itHAKOAfpWwfAnQI/ukN/DX4d0jukL+vqJJKjIz42BhiYyzaZYiIVIqIBYW7\nTzWzdiF2uRz4hwceiDHTzBqbWUt33xTquAs37qDTI59VYqWVL6lhAqN/diZdWydGuxQRkQqL5p3Z\nrYH1JZazg+uOCAozux24HaBp61QeGtypSgosjyWbdjJ23kaG/nk6N/Ruw++GdqFufGy0yxIRKbca\nMYWHu78KvAqQnp7ud/ZvH+WKQruzf3ue/89y/vXNOsZlbuShIZ24/sw26o4SkRopmlc9bQBSSiwn\nB9fVeJ1bnsDffprOqBtOZ9feQh7+eCFnPjmR/zthCXsKqvf4iojI4aIZFGOBnwavfuoD7ChrfKKm\nGdq9FUt/P5iHBneisNh5deoqznxyIiM+nM+C7B3RLk9EJCwWGEuOwIHN3gH6A0nA98CjQDyAu79s\nZkbgqqjBQB7wM3cvc1rY9PR0r6mzx3655Hvu/tdc9gSv2joztQlDu7ek7ylJtG/WMMrViUhtZmZz\n3D29XO+NVFBESk0Oiv3mrf+BJz9ZwtptuXy/cy8AP0prxfABHRQYIhIRCooa7OuVOTz16RLmB7ui\nurVOZNgZKRr8FpFKpaCoBdZvy+Of36zllSmrAEhpUo+f903lvFObkZrUgEBPnYhI+SgoapHiYucv\nk7N48cssCoqKATg5qQHDzkhhQOeTOKW5uqZE5NgpKGqpRRt3MG7eJj5buIk1OXkAJDWsw1W9WnPW\nyU05u30SCXGa11FEyqagOA6sy8njjRmrmbkqh6Xf7QIgIS6GTi0acUGn5lybnkKrxvWiXKWIVFcK\niuPMdzvymZG1lTdmrOb7nfls3V0ABM42ep/chCFdW9DvlGYk1o+PcqUiUl0oKI5zCzfsYNLSzUxZ\nvoX5G3ZQUFhMQlwMg09rwYDOzbm4W0viY9VFJXI8U1DIAUXFzvSsrYyft5H352QfWH/uqc0Y0rUF\nZ6Y2IbVpA2J06a3IcUVBIUe1r6iY8fM3Mn1FDlNXbGHLrsDNfUkNE7gmPYWfntWWloka1xA5Higo\nJCwzV+WQsWYb/12Zw39X5gDQr0MSz13bg+aN6ka5OhGJJAWFHLNl3+3ixa9W8Mn8TcTHGpd0a8mD\ngzvpyimRWkpBIeW2emsur05dyfsZ2RS7c06HZjw4qKOezidSyygopMLWbM3liU+WMHHJ9wBc0q0l\nv7m4E8kn1o9yZSJSGRQUUmlWfL+L575YzmeLvgPg4Us6c+0ZKZxQV/dkiNRkCgqpdNNXbOWut+ew\nM7+QhNgYPrzzbLolqztKpKaqSFDoLiw5qnM6JDHv0Yt4aHAnCoqKuXTUdO54aw5FxTXrFwsRqTgF\nhZTKzLizf3vGDz8HgM8Wfcf5z05mxfe7olyZiFQlBYWUqWvrRFY/dTFPXdmNddvyGPjHqTz/xbJo\nlyUiVURBIWExM64/sw3v3t4HgBe/yuJX72WyI29flCsTkUhTUMgx6XNyU768/zw6tWjEv7/dwOAX\npvLfrK3RLktEIkhBIcesfbOGfHbfuYz+2Rn8kLePG177htemrYp2WSISIQoKKbf+HZvz5f3ncepJ\nDXnikyXc9+5c9hYWRbssEalkCgqpkFaN6zHhnn5c1TOZjzM3MuRP05i2Yku0yxKRSqSgkAqLi43h\nuWt78PAlndmeV8BPXp/Fz0fPZv22vGiXJiKVQEEhlebWfifz1f39ueWcVL5aupkBz03hzRmro12W\niFSQgkIq1YkNEnhkaBemPXg+rU+sx2PjFvPgB/PYnlsQ7dJEpJwUFBIRKU3q88X/nMv1Z7bhvYxs\nBv5xCm9/s5aaNreYiCgoJILiY2N46spujLv7HE6sn8BvP1rIkBem8f3O/GiXJiLHQEEhEdctOZEJ\n9/bjzv7tWfrdLoa98jWrtuyOdlkiEiYFhVSJ+NgYHhrcib/e2JM1OXlc8NwUXpqUpa4okRpAQSFV\naki3lnx459kA/OHzZfzk9Vlkb9dltCLVmYJCqlyvtiey4skh/PL89kzP2sqA56bw2rRVFOtZFyLV\nUkSDwswGm9kyM8sysxFH2d7GzCaZ2Vwzm29mF0eyHqk+4mNjeGBQJ8be3ZekhnV44pMl9HriP6zL\n0dmFSHUTsaAws1jgJWAI0AW43sy6HLbbw8B77n46cB3wl0jVI9VT9+TGTH6gPz/vm8r2vH2c+4dJ\nvDVzbbTLEpESInlGcSaQ5e6r3L0AeBe4/LB9HDgh+DoR2BjBeqSaio+N4XeXduHjX/YF4JGPF/LP\nmbrnQqS6iGRQtAbWl1jODq4raSTwYzPLBiYAw492IDO73cwyzCxjyxZNOFdbpaU0ZtqD5xMbYzz8\n8UIe/GC+xi1EqoFoD2ZfD4x292TgYuAtMzuiJnd/1d3T3T29WbNmVV6kVJ2UJvVZ/sQQbj67HR98\nm815z05im6b/EImqSAbFBiClxHJycF1JtwDvAbj710BdICmCNUkNEBtjPHppFx4c1In12/bQ8/f/\nYczsddEuS+S4FcmgmA10MLNUM0sgMFg99rB91gEDAMysM4GgUN+SYGbc2b899w7oAMBDHy6g3YhP\nyN1bGOXKRI4/EQsKdy8E7gY+B5YQuLppkZk9bmaXBXe7H7jNzOYB7wA3u0YwpYT/GXgqix8fRIwF\nli98fgqzVm+LblEixxmraT+X09PTPSMjI9plSBR8PHcD943JBODCzifxx2E9aFQ3PspVidQMZjbH\n3dPL895oD2aLhO1Hp7dm0WOD+Emftkxc8j3dRn7BXyevjHZZIrWegkJqlAZ14vj9j7ryyk96AfD0\nZ0u5+IVp/JCnK6NEIkVBITXSoNNaMO93F5GW0pjFm3aS9vh/+M2/55O/ryjapYnUOgoKqbES68fz\n8S/7cs8FpwDwzqz1dB/5BWPn6QZ/kcqkwWypFdydUV9lMWpSFnsLiwH407A0Lk9rhZlFuTqR6NNg\nthz3zIzhAzowf+RFtDihLgD3jcnk4hen88Wi7zRvlEgF6IxCaqX8fUW8PGUl//h67YEpQB4c3JFh\n6Sk0bVgnytWJVL2KnFEoKKRWyysoZMSHC44Yt5g/8iJO0D0YchxRUIiUwd35fNH33PHPOQfWdWud\nyFu3nEnj+glRrEykamiMQqQMZsbgri1Y87+XMOqG0wFYsGEHaY//h9+PX0xhUXGUKxSpvnRGIcel\nfUXF/G3aKt6euY4NP+wBYFh6Co9dfhp142OjXJ1I5VPXk0g5FRc7785ez//5aAEAcTHGc9f24LIe\nuqxWahcFhUgFuTtvzljDWzPXsnprLqe1OoGreyVz01ntiIlRYEjNp6AQqST7iooZPWMNT326hGKH\nNk3qc0PvNtx6TipxsRrSk5pLQSFSyYqKnf+XuYE/TlzO+m2BMYwrTm/Nk1d0pX5CXJSrEzl2uupJ\npJLFxhhX9kxm6gPn8+ilXQD4aO4G+v9hMu/NXk9Rcc36BUukInRGIRKmSUs3c++7c9mZX0jLxLpc\n3SuZYWekkHxi/WiXJlImdT2JVJHiYueLxd/x7uz1TF2+hf0nFjf0bsP9A0/V9CBSbSkoRKJg/bY8\n/s9HC5i2Yush6//203QGdjkpSlWJHJ2CQiSK3J33M7J58MP5B9b1Tm3C0B6t+FFaKz3XW6oFBYVI\nNbF5Zz7vzl7P8/9ZDkCMwaU9WnF2+6Zc1TNZl9hK1CgoRKqZ4mJn3PyNvDtrPV+vyjlkW/+OzfjL\njT11ma1UKQWFSDW2e28hj49bRPb2Pfx35cHQSEtpTO/UJvQ5uSn9OzbTlCESUQoKkRpi0449jJ+3\niSWbdvLvuRsO2dapRSOaNEjguWt70DKxXpQqlNpKQSFSQ63asptRX2WxaUf+EV1UPds05pfnn8KA\nzrqCSipOQSFSCxQXOx9nbuDhjxeSV1B0xPaOJzXitZvSSWmiG/zk2CkoRGqhzbvy+evklbw5Y80h\n6xvViWNoj1ac2yGJ7imNad1Y3VRSNgWFSC3n7qzYvJtx8zayaONOZq3exu69hYfs88xV3bm4e0sa\n1tHVVHIkBYXIcWZfUTH//jabkWMXs2ffod1UbZrU55TmDbm4W0uuPL21nqchgIJC5Li3e28hc9Zu\nZ9LSzXy+6Ds27cg/ZPuFnZtz89mpnJF6InXi9KjX45GCQkQOsS4nj79MzuLd2euP2Jaa1IB9RcU8\ndWU3Tm9zorqqjhNVEhRm1hpoCxz4Vrn71PJ8aEUoKESO3f77N6au2HLEJIYAV/dKZvBpLTirfVMa\nKDhqpYgHhZk9DQwDFgP7O0Td3S8r432DgReAWOA1d//fo+xzLTAScGCeu98Q6pgKCpGK+25HPu9l\nrOcvk7PI31d8xPYBnZozuGsLzj21GSedUDcKFUplq4qgWAZ0d/e9x1BULLAcGAhkA7OB6919cYl9\nOgDvARe4+3Yza+7um0MdV0EhUvl25u/j65U5jBy76Ijxjf06tWjE1b2SuTytNc0a6bkbNU1VBMWn\nwDXuvvsYijoLGOnug4LLvwFw96dK7PMMsNzdXwv3uAoKkcjLKyjkv1k5vDxlJbvyC1n2/a5S972z\nf3uGpafQtml9zVdVjVUkKMLtjMwDMs3sS+DAWYW73xPiPa2BkiNp2UDvw/Y5FcDMZhDonhrp7p+F\nWZOIREj9hDgu7HISF5Z4ANPmXfl8u/YHXpu2ioy12w+s/+vklfx18soDy31PaUqnFidwdvumtEys\nR2pSA+ol6EqrmizcoBgb/BOJz+8A9AeSgalm1s3dfyi5k5ndDtwO0KZNmwiUISJlad6oLoO7tmBw\n1xYH1m3asYeMNdv57UcL2JkfuAFwRlYOM7JyeH36agDiYozC4DNjr+qZTIM6sfysbyqpSQ2q/h8h\n5XIsVz0lEDwDAJa5+74y9g+n6+ll4Bt3fzO4/CUwwt1nl3ZcdT2JVG/uztbdBSzauIMNP+xh7rof\n+GBO9hH77Q+Q5o3q0LBOHP07NmdA5+b0ansideN1BlLZqmKMoj/wd2ANYEAKcFOoy2PNLI7AYPYA\nYAOBwewb3H1RiX0GExjgvsnMkoC5QJq75xztmKCgEKmp3J2NO/J58IN5FBU78bExR71Ut6R2TevT\nIrEuN/ZuS1pwXivdaV4+VTFG8RxwkbsvC37gqcA7QK/S3uDuhWZ2N/A5gfGHN9x9kZk9DmS4+9jg\ntovMbP9ltw+ECgkRqbnMjNaN6/H2rX2O2Ja7t5BpK7bw18kr+WHPPtbm5AGwJiePNTl5zFy17ajH\nvKF3G05PaUy35EROTmpIQpweNRsJ4Z5RzHf37mWtqwo6oxA5vmzemc/iTTvJ3r6HrM27+fe32QfG\nQ0JpmViX5o3qcHWvZM4+JYm2Teof188sr4qupzeAYuCfwVU3ArHu/vPyfGhFKChEBALP79iau5f5\n63eQsXY7U5ZvYcmmnaXuH2NQXOLH3U/6tOXKnq1JaVKfpIa1/76QqgiKOsAvgXOCq6YBfzmWG/Aq\ni4JCRMKxp6CINTm5rM3JY8eeAhZv3Mnfv15b6v7xsUZivQT2FBRyRc/WXHF6MilN6tGsYZ1acX+I\nJgUUETkGObv3Mj1rK1t27eWN6avZuCOfJg0S2JZbcMS+ifXiSawXz7pteSQ1TOCX559Cx5MacXKz\nhrRIrDnTm0QsKMzsPXe/1swWEJiL6RAaoxCR2mZfUTGbfshn6Xc72fDDHj5b+B3Lv9/F9rzS7wjo\n1KIRXVqewKU9WtGqcT3aNKlf7W4yjGRQtHT3TWbW9mjb3b3087gIUVCISLTsKShi8aadrNqym1em\nrmJvYRHrt+0J+Z7EevHkFRTy9FXdOe/UZjSN0nhIVYxRNAD2uHtx8NLYTsCnZd10FwkKChGpjrbn\nFrBk004Wb9rJ6q25vP3NulL3TWlSD8OoExfDfReeSnq7EyM+S29VBMUcoB9wIjCDwM1zBe5+Y3k+\ntCIUFCJSk+QVFLIgewcrNu/m4Y8XcmHnk/hu5x4WbjjyCi0zOKNtE9bk5PLbSzrT95SkSrsiqyqC\n4lt372lmw4F67v6MmWW6e1p5PrQiFBQiUhu4Ows37CR7ex4PfTifnfmFNEiIJbeg6Kj7d2jekEt7\ntKJfhyTSUhof85VYVREUc4G7gD8CtwTvsF7g7t3K86EVoaAQkdpuy669ZKzZxtQVW3lnVuldWDEG\n799xFt2TGxNfxs2EVREU5wH3AzPc/WkzOxm4r4xpxiNCQSEix6OCwmIWbPiBN2as4ZP5m466T7fW\niYy87DR6tT3xiG26j0JE5Di0ZddeJi/bzAMfzD9i22mtTuDtW3vTuH4CENnLY//k7veZ2TiOfh9F\nyGdmR4KCQkTk6Oas3c7r01cxYcF3B9bdfHY7HhzckQZ14iM2e+xbwb+fLc/BRUSk6vRqeyK92gYm\n9Z6zdhv3vJPJ6P+uYUZW6OncyxIyKNx9TvBlBsH7KADMLBao/bNoiYjUUL3aNmHGiAt4Z9Y6fvPv\nBRU6Vrhz7n4J1C+xXA+YWKFPFhGRiDvnlKQKHyPcoKjr7rv3LwRf1w+xv4iIVAMN6oT7fLrShRsU\nuWbWc/+CmfUCQk9wIiIiUVcZT/0LN2ruA943s40EnpndAhhW4U8XEZGIqlNVQeHus82sE9AxuGpZ\nNCYEFBGRYxMXU/GHLoUVNWZWH3gIuNfdFwLtzGxohT9dREQiysxoVMFxinDPSd4ECoCzgssbgCcq\n9MkiIlIlfndplwq9P9ygaO/uzwD7ANw9j8BYhYiIVHPXpKdU6P3hBkWBmdUjOI2HmbUH9lbok0VE\npEYIt+PqUeAzIMXM3gb6AjdHqigREak+ygwKCzwdYylwJdCHQJfTve5esclDRESkRigzKNzdzWxC\n8CFFn1RBTSIiUo2EO0bxrZmdEdFKRESkWgp3jKI38GMzWwPkEuh+cnfvHqnCRESkegg3KAZFtAoR\nEam2QgaFmdUF7gBOARYAr7t7YVUUJiIi1UNZYxR/B9IJhMQQ4LmIVyQiItVKWV1PXYJXO2FmrwOz\nIl+SiIhUJ2WdURyYIVZdTiIix6eygqKHme0M/tkFdN//2sx2lnVwMxtsZsvMLMvMRoTY7yozczNL\nP9Z/gIiIRFbIrid3jy3vgc0sFngJGAhkA7PNbKy7Lz5sv0bAvcA35f0sERGJnIo/+qh0ZwJZ7r7K\n3QuAd4HLj7Lf74GngfwI1iIiIuUUyaBoDawvsZwdXHdA8DncKe4ecmoQM7vdzDLMLGPLli2VX6mI\niJQqkkERkpnFAM8D95e1r7u/6u7p7p7erFmzyBcnIiIHRDIoNgAln5aRHFy3XyOgKzA5ODVIH2Cs\nBrRFRKqXSAbFbKCDmaWaWQJwHTB2/0Z33+HuSe7ezt3bATOBy9w9I4I1iYjIMYpYUATvu7gb+BxY\nArzn7ovM7HEzuyxSnysiIpUr3EkBy8XdJwATDlv3u1L27R/JWkREpHyiNpgtIiI1g4JCRERCUlCI\niEhICgoREQlJQSEiIiEpKEREJCQFhYiIhKSgEBGRkBQUIiISkoJCRERCUlCIiEhICgoREQlJQSEi\nIiEpKEREJCQFhYiIhKSgEBGRkBQUIiISkoJCRERCUlCIiEhICgoREQlJQSEiIiEpKEREJCQFhYiI\nhKSgEBGRkBQUIiISkoJCRERCUlCIiEhICgoREQlJQSEiIiEpKEREJCQFhYiIhKSgEBGRkCIaFGY2\n2MyWmVmWmY04yvZfmdliM5tvZl+aWdtI1iMiIscuYkFhZrHAS8AQoAtwvZl1OWy3uUC6u3cHPgCe\niVQ9IiJSPpE8ozgTyHL3Ve5eALwLXF5yB3ef5O55wcWZQHIE6xERkXKIZFC0BtaXWM4OrivNLcCn\nR9tgZrebWYaZZWzZsqUSSxQRkbJUi8FsM/sxkA784Wjb3f1Vd0939/RmzZpVbXEiIse5uAgeewOQ\nUmI5ObjuEGZ2IfBb4Dx33xvBekREpBwieUYxG+hgZqlmlgBcB4wtuYOZnQ68Alzm7psjWIuIiJRT\nxILC3QuBu4HPgSXAe+6+yMweN7PLgrv9AWgIvG9mmWY2tpTDiYhIlESy6wl3nwBMOGzd70q8vjCS\nny8iIhVXLQazRUSk+lJQiIhISAoKEREJSUEhIiIhKShERCQkBYWIiISkoBARkZAUFCIiEpKCQkRE\nQlJQiIhISAoKEREJSUEhIiIhKShERCSkiM4eW1X27dtHdnY2+fn50S5Faqi6deuSnJxMfHx8tEsR\nqXZqRVBkZ2fTqFEj2rVrh5lFuxypYdydnJwcsrOzSU1NjXY5ItVOreh6ys/Pp2nTpgoJKRczo2nT\npjojFSlFrQgKQCEhFaLvj0jpak1QiIhIZCgoKklsbCxpaWl07dqVa665hry8vAofMyMjg3vuuafU\n7Rs3buTqq6+u8OcATJ48mcTERNLS0ujUqRO//vWvK+W4Jd1888188MEHAPTv35+MjIxK/wwRqXwK\nikpSr149MjMzWbhwIQkJCbz88suHbHd3iouLj+mY6enpvPjii6Vub9Wq1YEfvJWhX79+ZGZmMnfu\nXMaPH8+MGTMq7dhVoaioKNoliNRKteKqp5IeG7eIxRt3Vuoxu7Q6gUcvPS3s/fv168f8+fNZs2YN\ngwYNonfv3syZM4cJEyawbNkyHn30Ufbu3Uv79u158803adiwIbNnz+bee+8lNzeXOnXq8OWXXzJn\nzhyeffZZxo8fz5QpU7j33nuBQH/61KlTycnJYejQoSxcuJD8/HzuvPNOMjIyiIuL4/nnn+f8889n\n9OjRjB07lry8PFauXMkVV1zBM888E7L+evXqkZaWxoYNGwDIzc1l+PDhLFy4kH379jFy5Eguv/xy\nioqKeOihh/jss8+IiYnhtttuY/jw4Tz++OOMGzeOPXv2cPbZZ/PKK6+EPQZwtHb48MMPycjIYNSo\nUQAMHTqUX//61/Tv35+GDRvyi1/8gokTJ3LNNdcwb9483n//fSBwlrS//b744oujtruIlE1nFJWs\nsLCQTz/9lG7dugGwYsUK7rrrLhYtWkSDBg144oknmDhxIt9++y3p6ek8//zzFBQUMGzYMF544QXm\nzZvHxIkTqVev3iHHffbZZ3nppZfIzMxk2rRpR2x/6aWXMDMWLFjAO++8w0033XTgKp7MzEzGjBnD\nggULGDNmDOvXrw/5b9i+fTsrVqzg3HPPBeDJJ5/kggsuYNasWUyaNIkHHniA3NxcXn31VdasWUNm\nZibz58/nxhtvBODuu+9m9uzZLFy4kD179jB+/Piw2i6cdjhcbm4uvXv3Zt68eYwYMYJvvvmG3Nxc\nAMaMGcN1113H1q1bj9ruIhKeWndGcSy/+VemPXv2kJaWBgTOKG655RY2btxI27Zt6dOnDwAzZ85k\n8eLF9O3bFwj8YDzrrLNYtmwZLVu25IwzzgDghBNOOOL4ffv25Ve/+hU33ngjV155JcnJyYdsnz59\nOsOHDwegU6dOtG3bluXLlwMwYMAAEhMTAejSpQtr164lJSXliM+YNm0aPXr0YMWKFdx33320aNEC\ngC+++IKxY8fy7LPPAoHLkdetW8fEiRO54447iIsLfI2aNGkCwKRJk3jmmWfIy8tj27ZtnHbaaVx6\n6aVltmE47XC42NhYrrrqKgDi4uIYPHgw48aN4+qrr+aTTz7hmWeeYcqUKUdtdxEJT60LimjZP0Zx\nuAYNGhx47e4MHDiQd95555B9FixYUObxR4wYwSWXXMKECRPo27cvn3/+OXXr1g2rtjp16hx4HRsb\nS2FhIR999BGPPfYYAK+99hoQCLjx48ezevVq+vTpw7XXXktaWhruzocffkjHjh3L/Kz8/Hzuuusu\nMjIySElJYeTIkRW+PyEuLu6Q8Z2Sx6tbty6xsbEHlq+77jpGjRpFkyZNSE9Pp1GjRqW2u4iER11P\nVahPnz7MmDGDrKwsINBtsnz5cjp27MimTZuYPXs2ALt27aKwsPCQ965cuZJu3brx0EMPccYZZ7B0\n6dJDtvfr14+3334bgOXLl7Nu3bqQP9ivuOIKMjMzyczMJD09/ZBtqampjBgxgqeffhqAQYMG8ec/\n/xl3B2Du3LkADBw4kFdeeeVArdu2bTvwQzwpKYndu3cf02B7ae3Qrl07MjMzKS4uZv369cyaNavU\nY5x33nl8++23/O1vf+O6664DSm93EQmPgqIKNWvWjNGjR3P99dfTvXt3zjrrLJYuXUpCQgJjxoxh\n+PDh9OjRg4EDBx7xW/if/vQnunbtSvfu3YmPj2fIkCGHbL/rrrsoLi6mW7duDBs2jNGjRx9yJnGs\n7rjjDqZOncqaNWt45JFH2LdvH927d+e0007jkUceAeDWW2+lTZs2dO/enR49evCvf/2Lxo0bc9tt\nt9G1a1cGDRp0oBspHKW1Q9++fUlNTaVLly7cc8899OzZs9RjxMbGMnToUD799FOGDh0KlN7uIhIe\n2/9bYk2Rnp7uh19/v2TJEjp37hyliqS20PdIajMzm+Pu6WXveSSdUYiISEgKChERCanWBEVN60KT\n6kXfH5HS1YqgqFu3Ljk5OfrPLuWy/3kU4V5uLHK8qRX3USQnJ5Odnc2WLVuiXYrUUPufcCciR6oV\nQREfH68nk4mIREhEu57MbBd6l0MAAAXRSURBVLCZLTOzLDMbcZTtdcxsTHD7N2bWLpL1iIjIsYtY\nUJhZLPASMAToAlxvZl0O2+0WYLu7nwL8EXg6UvWIiEj5RPKM4kwgy91XuXsB8C5w+WH7XA78Pfj6\nA2CA6ZmUIiLVSiTHKFoDJeezzgZ6l7aPuxea2Q6gKbC15E5mdjtwe3Bxr5ktjEjFNU8Sh7XVcUxt\ncZDa4iC1xUFlz+pZihoxmO3urwKvAphZRnlvQ69t1BYHqS0OUlscpLY4yMzK/ezhSHY9bQBKPvQg\nObjuqPuYWRyQCOREsCYRETlGkQyK2UAHM0s1swTgOmDsYfuMBW4Kvr4a+Mp115yISLUSsa6n4JjD\n3cDnQCzwhrsvMrPHgQx3Hwu8DrxlZlnANgJhUpZXI1VzDaS2OEhtcZDa4iC1xUHlbosaN824iIhU\nrVox15OIiESOgkJEREKqtkGh6T8OCqMtfmVmi81svpl9aWZto1FnVSirLUrsd5WZuZnV2ksjw2kL\nM7s2+N1YZGb/quoaq0oY/0famNkkM5sb/H9ycTTqjDQze8PMNpd2r5kFvBhsp/lmVvpzhUty92r3\nh8Dg90rgZCABmAd0OWyfu4CXg6+vA8ZEu+4otsX5QP3g6zuP57YI7tcImArMBNKjXXcUvxcdgLnA\nicHl5tGuO4pt8SpwZ/B1F2BNtOuOUFucC/QEFpay/WLgU8CAPsA34Ry3up5RaPqPg8psC3ef5O55\nwcWZBO5ZqY3C+V4A/J7AvGH5VVlcFQunLW4DXnL37QDuvrmKa6wq4bSFAycEXycCG6uwvirj7lMJ\nXEFamsuBf3jATKCxmbUs67jVNSiONv1H69L2cfdCYP/0H7VNOG1R0i0EfmOojcpsi+CpdIq7f1KV\nhUVBON+LU4FTzWyGmc00s8FVVl3VCqctRgI/NrNsYAIwvGpKq3aO9ecJUEOm8JDwmNmPgXTgvGjX\nEg1mFgM8D9wc5VKqizgC3U/9CZxlTjWzbu7+Q1Srio7rgdHu/pyZnUXg/q2u7l4c7cJqgup6RqHp\nPw4Kpy0wswuB3wKXufveKqqtqpXVFo2ArsBkM1tDoA92bC0d0A7ne5ENjHX3fe6+GlhOIDhqm3Da\n4hbgPQB3/xqoS2DCwONNWD9PDlddg0LTfxxUZluY2enAKwRCorb2Q0MZbeHuO9w9yd3buXs7AuM1\nl7l7uSdDq8bC+T/yMYGzCcwsiUBX1KqqLLKKhNMW64ABAGbWmUBQHI/PTh4L/DR49VMfYIe7byrr\nTdWy68kjN/1HjRNmW/wBaAi8HxzPX+ful0Wt6AgJsy2OC2G2xefARWa2GCgCHnD3WnfWHWZb3A/8\nzcz+h8DA9s218RdLM3uHwC8HScHxmEeBeAB3f5nA+MzFQBaQB/wsrOPWwrYSEZFKVF27nkREpJpQ\nUIiISEgKChERCUlBISIiISkoREQkJAWFyGHMrMjMMs1soZmNM7PGlXz8m81sVPD1SDP7dWUeX6Sy\nKShEjrTH3dPcvSuBe3R+Ge2CRKJJQSES2teUmDTNzB4ws9nBufwfK7H+p8F188zsreC6S4PPSplr\nZhPN7KQo1C9SYdXyzmyR6sDMYglM+/B6cPkiAnMlnUlgPv+xZnYugTnGHgbOdvetZtYkeIjpQB93\ndzO7FXiQwB3CIjWKgkLkSPXMLJPAmcQS4D/B9RcF/8wNLjckEBw9gPfdfSuAu+9/HkAyMCY4338C\nsLpqyhepXOp6EjnSHndPA9oSOHPYP0ZhwFPB8Ys0dz/F3V8PcZw/A6PcvRvwCwIT0YnUOAoKkVIE\nnxp4D3B/cCr7z4Gfm1lDADNrbWbNga+Aa8ysaXD9/q6nRA5O4XwTIjWUup5EQnD3uWY2H7je3d8K\nTlH9dXCW3t3Aj4MzlT4JTDGzIgJdUzcTeKra+2a2nUCYpEbj3yBSUZo9VkREQlLXk4iIhKSgEBGR\nkBQUIiISkoJCRERCUlCIiEhICgoREQlJQSEiIiH9f0VpQyRqSrmvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "precision\n",
            "1.0\n",
            "recall\n",
            "0.09987901171676006\n",
            "threhold\n",
            "0.99998844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1EZAW3iPGqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b080bc79-bbea-442a-f6f3-db6c32d51d30"
      },
      "source": [
        "y_true[y_true==1].size,y_scores.size ,y_scores[y_scores>threshold].size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62816, 143712, 6262)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z94nQhyFIYEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkpYtL-6z1ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing \n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "# # model loaded\n",
        "# model=load_model_arch('m1')\n",
        "# model=load_model_ckpt(model,'m1',45)\n",
        "# opt_th = 0.99998844\n",
        "\n",
        "def get_stock_hist_exact(code,start,end):\n",
        "  try :\n",
        "    info = pdr.get_data_yahoo(code, \n",
        "                        start=start, \n",
        "                        end=end)\n",
        "  except:\n",
        "    df_empty = pd.DataFrame({'A' : []})\n",
        "    return df_empty\n",
        "\n",
        "  info = info.loc[start:end]\n",
        "  return info\n",
        "\n",
        "def is_dayoff(day):\n",
        "\n",
        "  holidays=['2019-12-25','2019-12-31','2020-01-01','2020-01-24','2020-01-27']\n",
        "  \n",
        "  if((day.weekday()==5) or (day.weekday()==6) or (day.strftime('%Y-%m-%d') in holidays)):\n",
        "    return True\n",
        "  else:\n",
        "    #print (day,day in holidays)\n",
        "    return False\n",
        "\n",
        "def is_buy(model,th,code,start,end): # code, (30,2) feature\n",
        "   hist = get_stock_hist_exact(code,start,end)\n",
        "\n",
        "   if(hist.empty):\n",
        "    return 0,0\n",
        "\n",
        "   feature = hist.iloc[:-1,4:6]\n",
        "   if(feature.shape[0]!=30):\n",
        "     return 0,0\n",
        "\n",
        "   min_max_scaler = preprocessing.MinMaxScaler()\n",
        "   scaled_feature = min_max_scaler.fit_transform(feature)\n",
        "\n",
        "   scaled_feature= np.array([scaled_feature])\n",
        "   pred=get_result(model,scaled_feature,th)\n",
        "\n",
        "   cur_val = hist.iloc[-2,5]\n",
        "   future_val = hist.iloc[-1,5]\n",
        "\n",
        "   profit = (future_val-cur_val)/(cur_val)\n",
        "\n",
        "   return pred,profit\n",
        "\n",
        "def get_result(model,scaled_feature,th):\n",
        "  pred = model.predict(scaled_feature, verbose=0)\n",
        "  result = pred > th\n",
        "\n",
        "  #print (result.shape)\n",
        "  pred = pred[:,1]\n",
        "  result = result[:,1]\n",
        "\n",
        "  return pred,result\n",
        "\n",
        "def back_test_onecode(code,start_datetime,end_datetime,model,th):\n",
        "  acc_val = 0\n",
        "  correct = 0\n",
        "  buy_cnt =0\n",
        "  win_ratio= 0\n",
        "\n",
        "  while(True):\n",
        "  \n",
        "    while(is_dayoff(start_datetime)):\n",
        "      start_datetime += datetime.timedelta(days=1)\n",
        "      \n",
        "    while(is_dayoff(end_datetime)):\n",
        "      end_datetime += datetime.timedelta(days=1)\n",
        "\n",
        "    print (str(start_datetime) +\"~\"+str(end_datetime))\n",
        "    buy,val=is_buy(model,th,code,start_datetime,end_datetime)\n",
        "\n",
        "    if(buy):\n",
        "      acc_val+=val\n",
        "      buy_cnt+=1\n",
        "      if(val>0):\n",
        "        correct+=1\n",
        "        win_ratio= (correct/buy_cnt)\n",
        "\n",
        "\n",
        "    print (buy,val,acc_val,win_ratio)\n",
        "\n",
        "    start_datetime += datetime.timedelta(days=1)\n",
        "    end_datetime += datetime.timedelta(days=1)\n",
        "\n",
        "def back_test_multicode(list,start_datetime,end_datetime,model,th):\n",
        "    #just test one day\n",
        "\n",
        "  total_acc_val = 0\n",
        "  correct = 0\n",
        "  acc_buy_cnt =0\n",
        "  win_ratio= 0\n",
        "\n",
        "  while(True):\n",
        "\n",
        "    acc_val=0\n",
        "    buy_cnt=0\n",
        "  \n",
        "    while(is_dayoff(start_datetime)):\n",
        "      start_datetime += datetime.timedelta(days=1)\n",
        "      \n",
        "    while(is_dayoff(end_datetime)):\n",
        "      end_datetime += datetime.timedelta(days=1)\n",
        "\n",
        "    print (str(start_datetime) +\"~\"+str(end_datetime))\n",
        "\n",
        "    for code in kospi_list:\n",
        "      buy,val=is_buy(model,th,code+\".KS\",start_datetime,end_datetime)\n",
        "\n",
        "      if(buy):\n",
        "        #print ('buy!')\n",
        "        print (code,val)\n",
        "        acc_val+=val\n",
        "\n",
        "        buy_cnt+=1\n",
        "        if(val>0):\n",
        "          correct+=1\n",
        "\n",
        "    if(buy_cnt!=0):\n",
        "      total_acc_val += (acc_val/buy_cnt)\n",
        "\n",
        "    acc_buy_cnt+= buy_cnt\n",
        "\n",
        "    win_ratio= (correct/acc_buy_cnt)\n",
        "    print (total_acc_val,acc_val,win_ratio)\n",
        "    start_datetime += datetime.timedelta(days=1)\n",
        "    end_datetime += datetime.timedelta(days=1)\n",
        "\n",
        "def plot_multi(data, cols=None, spacing=.1, **kwargs):\n",
        "\n",
        "    from pandas import plotting\n",
        "\n",
        "    # Get default color style from pandas - can be changed to any other color list\n",
        "    if cols is None: cols = data.columns\n",
        "    if len(cols) == 0: return\n",
        "    colors = getattr(getattr(plotting, '_matplotlib').style, '_get_standard_colors')(num_colors=len(cols))\n",
        "\n",
        "    # First axis\n",
        "    ax = data.loc[:, cols[0]].plot(label=cols[0], color=colors[0], **kwargs)\n",
        "    ax.set_ylabel(ylabel=cols[0])\n",
        "    lines, labels = ax.get_legend_handles_labels()\n",
        "\n",
        "    for n in range(1, len(cols)):\n",
        "        # Multiple y-axes\n",
        "        ax_new = ax.twinx()\n",
        "        ax_new.spines['right'].set_position(('axes', 1 + spacing * (n - 1)))\n",
        "        data.loc[:, cols[n]].plot(ax=ax_new, label=cols[n], color=colors[n % len(colors)], **kwargs)\n",
        "        ax_new.set_ylabel(ylabel=cols[n])\n",
        "\n",
        "        # Proper legend position\n",
        "        line, label = ax_new.get_legend_handles_labels()\n",
        "        lines += line\n",
        "        labels += label\n",
        "\n",
        "    ax.legend(lines, labels, loc=0)\n",
        "    return ax\n",
        "\n",
        "def backtest_code(code,start,end,model,th,duration):\n",
        "  hist = get_stock_hist_exact(code,start,end)\n",
        "\n",
        "  if(len(hist)<duration):\n",
        "    print ('it is no data')\n",
        "    return -1,-1\n",
        "\n",
        "  test_x =[]\n",
        "  test_y =[]\n",
        "  profit_y =[]\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "  for end_idx in range(duration,len(hist)):\n",
        "    feature = hist.iloc[end_idx-duration:end_idx,4:6] # (0~30)\n",
        "    cur_val = feature.iloc[-2,1]\n",
        "    future_val = feature.iloc[-1,1]\n",
        "\n",
        "    scaled_feature =min_max_scaler.fit_transform(feature)\n",
        "    label= scaled_feature[duration-1][1] -scaled_feature[duration-2][1]\n",
        "    if(label > 0):\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "    \n",
        "    test_x.append(scaled_feature[:-1])\n",
        "    test_y.append(label)\n",
        "    profit_y.append((future_val-cur_val)/(cur_val))\n",
        "\n",
        "  test_x = np.array(test_x)\n",
        "  test_y = np.array(test_y)\n",
        "\n",
        "  pred,result = get_result(model,test_x,th)\n",
        "\n",
        "  hist.loc[duration-1:-1,'pred'] = pred\n",
        "  hist.loc[duration-1:-1,'profit_y'] = profit_y\n",
        "\n",
        "  plot_multi(hist[['Adj Close','pred','profit_y']],figsize=(10,5))\n",
        "  plt.axhline(y=0.0, color='r', linewidth=1)\n",
        "  plt.show()\n",
        "\n",
        "  result = result*1\n",
        "\n",
        "  #print (hist)\n",
        "  print (test_y)\n",
        "  print (result)\n",
        "\n",
        "  precision=precision_score(test_y,result)\n",
        "  recall=recall_score(test_y,result)\n",
        "  print (\"precision :\"+str(precision))\n",
        "  print (\"recall:\"+str(recall))\n",
        "\n",
        "  return precision ,recall\n",
        "\n",
        "  #plt.plot(hist['Adj Close'],hist['pred'])\n",
        "\n",
        "  #  return pred,profit\n",
        "\n",
        "start_year= 2019\n",
        "start_month=11\n",
        "start_day=18\n",
        "\n",
        "end_year=2020\n",
        "end_month=2\n",
        "end_day=17\n",
        "\n",
        "duration = 31\n",
        "\n",
        "ss = datetime.datetime(start_year, start_month, start_day)\n",
        "se = datetime.datetime(end_year, end_month, end_day)\n",
        "\n",
        "model=load_model_arch('m1')\n",
        "model=load_model_ckpt(model,'m1',45)\n",
        "opt_th = 0.99998844\n",
        "#opt_th = 0.5\n",
        "\n",
        "#backtest_code('079160.KS',ss,se,model,opt_th,duration)\n",
        "\n",
        "\n",
        "# kospi_list = pd.read_csv(KOSPI_LIST_FILE,error_bad_lines=False)['종목코드']\n",
        "\n",
        "# precision_list =[]\n",
        "# recall_list = []\n",
        "\n",
        "# cnt = 0\n",
        "# total = len(kospi_list)\n",
        "\n",
        "# for code in kospi_list:\n",
        "\n",
        "#   print (str(cnt)+\"/\"+str(total))\n",
        "#   cnt+=1\n",
        "#   precision,recall=backtest_code(code+'.KS',ss,se,model,opt_th,duration)\n",
        "#   if(precision==-1 and recall ==-1):\n",
        "#     continue\n",
        "#   precision_list.append(precision)\n",
        "#   recall_list.append(recall)\n",
        "\n",
        "# print ('mean precision')\n",
        "# print (np.array(precision_list).mean())\n",
        "# print ('mean recall')\n",
        "# print (np.array(recall_list).mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvXvFtOyprX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22304ff2-adef-41c6-97c6-f0368448f464"
      },
      "source": [
        "def is_buy2(code,start,end,model,th,duration):\n",
        "  hist = get_stock_hist_exact(code,start,end)\n",
        "\n",
        "  hist = hist.loc[start:end]\n",
        "  #print (len(hist))\n",
        "  if(len(hist)<duration):\n",
        "    print ('it is no data')\n",
        "    return -1\n",
        "\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "  feature = hist.iloc[:,4:6] # (0~29)\n",
        "  scaled_feature =min_max_scaler.fit_transform(feature)\n",
        "  scaled_feature= np.array([scaled_feature])\n",
        "  pred,result = get_result(model,scaled_feature,th)\n",
        "\n",
        "  return result\n",
        "\n",
        "start_year= 2020\n",
        "start_month=1\n",
        "start_day=3\n",
        "\n",
        "end_year=2020\n",
        "end_month=2\n",
        "end_day=17\n",
        "\n",
        "duration = 30\n",
        "\n",
        "ss = datetime.datetime(start_year, start_month, start_day)\n",
        "se = datetime.datetime(end_year, end_month, end_day)\n",
        "\n",
        "model=load_model_arch('m1')\n",
        "model=load_model_ckpt(model,'m1',45)\n",
        "opt_th = 0.99998844\n",
        "#opt_th = 0.5\n",
        "\n",
        "\n",
        "kospi_list = pd.read_csv(KOSPI_LIST_FILE,error_bad_lines=False)['종목코드']\n",
        "\n",
        "precision_list =[]\n",
        "recall_list = []\n",
        "buycode_list = []\n",
        "\n",
        "cnt = 0\n",
        "total = len(kospi_list)\n",
        "\n",
        "for code in kospi_list:\n",
        "  print (cnt,total)\n",
        "  cnt+=1\n",
        "  result=is_buy2(code+'.KS',ss,se,model,opt_th,duration)\n",
        "  if(result == 1):\n",
        "    print (code)\n",
        "    buycode_list.append(code)\n",
        "  \n",
        "print (buycode_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 442: expected 12 fields, saw 13\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 803\n",
            "1 803\n",
            "2 803\n",
            "3 803\n",
            "4 803\n",
            "5 803\n",
            "6 803\n",
            "7 803\n",
            "8 803\n",
            "9 803\n",
            "10 803\n",
            "11 803\n",
            "12 803\n",
            "13 803\n",
            "14 803\n",
            "15 803\n",
            "16 803\n",
            "17 803\n",
            "18 803\n",
            "19 803\n",
            "20 803\n",
            "21 803\n",
            "22 803\n",
            "23 803\n",
            "24 803\n",
            "25 803\n",
            "26 803\n",
            "27 803\n",
            "28 803\n",
            "29 803\n",
            "30 803\n",
            "31 803\n",
            "32 803\n",
            "33 803\n",
            "34 803\n",
            "35 803\n",
            "36 803\n",
            "37 803\n",
            "38 803\n",
            "39 803\n",
            "40 803\n",
            "41 803\n",
            "42 803\n",
            "43 803\n",
            "44 803\n",
            "it is no data\n",
            "45 803\n",
            "46 803\n",
            "47 803\n",
            "48 803\n",
            "49 803\n",
            "50 803\n",
            "51 803\n",
            "52 803\n",
            "53 803\n",
            "54 803\n",
            "55 803\n",
            "56 803\n",
            "57 803\n",
            "58 803\n",
            "59 803\n",
            "60 803\n",
            "61 803\n",
            "62 803\n",
            "63 803\n",
            "it is no data\n",
            "64 803\n",
            "65 803\n",
            "66 803\n",
            "67 803\n",
            "68 803\n",
            "69 803\n",
            "70 803\n",
            "71 803\n",
            "72 803\n",
            "73 803\n",
            "74 803\n",
            "75 803\n",
            "76 803\n",
            "77 803\n",
            "78 803\n",
            "79 803\n",
            "80 803\n",
            "81 803\n",
            "82 803\n",
            "83 803\n",
            "84 803\n",
            "85 803\n",
            "86 803\n",
            "87 803\n",
            "88 803\n",
            "89 803\n",
            "90 803\n",
            "91 803\n",
            "92 803\n",
            "93 803\n",
            "94 803\n",
            "95 803\n",
            "96 803\n",
            "97 803\n",
            "98 803\n",
            "99 803\n",
            "100 803\n",
            "101 803\n",
            "102 803\n",
            "103 803\n",
            "104 803\n",
            "105 803\n",
            "106 803\n",
            "107 803\n",
            "108 803\n",
            "109 803\n",
            "110 803\n",
            "111 803\n",
            "112 803\n",
            "113 803\n",
            "114 803\n",
            "115 803\n",
            "116 803\n",
            "117 803\n",
            "118 803\n",
            "119 803\n",
            "120 803\n",
            "121 803\n",
            "122 803\n",
            "123 803\n",
            "124 803\n",
            "125 803\n",
            "126 803\n",
            "127 803\n",
            "128 803\n",
            "129 803\n",
            "130 803\n",
            "131 803\n",
            "132 803\n",
            "133 803\n",
            "134 803\n",
            "135 803\n",
            "it is no data\n",
            "136 803\n",
            "137 803\n",
            "138 803\n",
            "139 803\n",
            "140 803\n",
            "141 803\n",
            "142 803\n",
            "143 803\n",
            "144 803\n",
            "145 803\n",
            "146 803\n",
            "147 803\n",
            "148 803\n",
            "149 803\n",
            "150 803\n",
            "151 803\n",
            "152 803\n",
            "153 803\n",
            "154 803\n",
            "155 803\n",
            "156 803\n",
            "157 803\n",
            "158 803\n",
            "159 803\n",
            "160 803\n",
            "161 803\n",
            "162 803\n",
            "it is no data\n",
            "163 803\n",
            "164 803\n",
            "165 803\n",
            "166 803\n",
            "167 803\n",
            "168 803\n",
            "169 803\n",
            "170 803\n",
            "171 803\n",
            "172 803\n",
            "173 803\n",
            "174 803\n",
            "175 803\n",
            "176 803\n",
            "177 803\n",
            "178 803\n",
            "179 803\n",
            "180 803\n",
            "181 803\n",
            "182 803\n",
            "183 803\n",
            "184 803\n",
            "185 803\n",
            "186 803\n",
            "187 803\n",
            "188 803\n",
            "189 803\n",
            "190 803\n",
            "191 803\n",
            "192 803\n",
            "193 803\n",
            "194 803\n",
            "195 803\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}